\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={dissertation\_writeup\_draft},
            pdfauthor={Alassane Ndour},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{dissertation\_writeup\_draft}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Alassane Ndour}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{23/08/2019}


\begin{document}
\maketitle

\hypertarget{introduction-and-objectives}{%
\section{Introduction and
Objectives}\label{introduction-and-objectives}}

\hypertarget{background-to-the-problem}{%
\subsection{background to the problem}\label{background-to-the-problem}}

\begin{itemize}
\tightlist
\item
  Importance of growth models
\item
  Noisy environment - Systematic error
\item
  Classification using Bayes factor - e.g.~See for a dataset classified
  as linear which model seems to fit (frequentist) better which will be
  selected by BF and by how much while varying noise
\end{itemize}

\hypertarget{reasons-for-the-choice-of-project}{%
\subsection{Reasons for the choice of
project}\label{reasons-for-the-choice-of-project}}

\begin{itemize}
\tightlist
\item
  Application in biology and economics
\item
  Contribution to literature as unexplored method - combination of Bayes
  factor and Harris paper
\item
  Study of noise to signal ratio in classification and different types
  of noise
\end{itemize}

\hypertarget{identification-of-the-projects-beneficiaries}{%
\subsection{Identification of the project's
beneficiaries}\label{identification-of-the-projects-beneficiaries}}

\begin{itemize}
\tightlist
\item
  Commercial partner (probably not but mught get data from them)
\item
  Literature as an empirical analysis of Bayesian classification of
  growth using different models
\end{itemize}

\hypertarget{objectives-and-metrics}{%
\subsection{Objectives and metrics}\label{objectives-and-metrics}}

\begin{itemize}
\tightlist
\item
  A Classification framework which should include :

  \begin{itemize}
  \tightlist
  \item
    A classification between different models
  \item
    The ``certainty'' of classification - TBD how we can quantify this
  \item
    An estimation of the parameters of the model - with the
    ``certainty'' of estimation
  \item
    An identification of the systematic error
  \end{itemize}
\end{itemize}

\hypertarget{broad-methods-and-how-they-answer-goal}{%
\subsection{Broad methods and how they answer
goal}\label{broad-methods-and-how-they-answer-goal}}

\begin{itemize}
\item
  Curve fitting :

  \begin{itemize}
  \tightlist
  \item
    Fit a linear and a logistic and classify depending on the error. See
    how as you increase the variance of the error, the classification
    changes (currently doing)
  \end{itemize}
\item
  Bayesian approach :

  \begin{itemize}
  \item
    Estimate the distribution of the parameters (we should get the
    ``certainty'' from here) of a Bayesian linear regression, sigmoid
    function and then add the algorithm set by Harris (his calculation
    was for a sigmoid. Might have to do it for a linear regression) and
    compare the models using Bayes factor.
  \item
    Does the model that fits the most correspond to the correct
    functional form?
  \item
    See if as you change error the systematic error is caught by the
    Harris algo and how the model selection varies
  \end{itemize}
\item
  Compare the two approches : how do they compare ? In terms of
  classification error rate for instance
\item
  Furthermore, there have been interesting developments in combining
  Bayesian methods and cross validation as they are not mutually
  exclusive methods and can contribute to robust estimates. Such works
  include Bürkner et al. (2019) where the authors aim to improve upon
  leave-future-out cross-validation (LFO-CV) - an adaptation of
  leave-one-out cross-validation (LOO-CV) to timeseries - to reduce
  computation time.
\end{itemize}

\hypertarget{context-literature}{%
\section{Context (Literature)}\label{context-literature}}

\begin{itemize}
\item
  Ed Harris
\item
  LOO-CV
\item
  Bayesian books
\item
  Bürkner et al. (2019)
\item
  Claeskens and Lid Hjort (2010) (Model selection)
\item
\end{itemize}

\hypertarget{data}{%
\section{Data}\label{data}}

The data used in this project was generated data. There are several
practical and methodological reasons for doing so. First,
methodogically, generating data makes sense. As advised by Kéry and
Royle (2016) as this offers a ideal control environment under which
parameters and hyper-parameters are known. Furthermore, in growth cell
literature, from which this project stems (e.g.~Harris et al. (2016))
synthetic data is standard practice. Second, data from the commercial
partner that was meant was to be analysed here was unavailable due to
legal restrictions and no open source equivalents were found. As the
synthetic data is at the heart of the analysis this section will
describe in greater detail the data meant to be mimiced and the
process/tools used to do so.

The type of data meant to be mimiced in this project is the similar to a
cell counting process. The context posed by the commercial partner was
the following : At any time \texttt{t} we must be able to estimate the
number of a given cells that we wish to count. We have knowledge of the
growth function that the cells take (i.e. \texttt{f(t)}). Now we know
that introducing an agent in our cell sample alters the growth path to
another growth process (\texttt{g(t)}). Given this we should be able to
obtain the number of cells for any given time if we have knowledge of
the presence of the agent. However if we do not know if the agent has
been introduced in the sample then we must select whether we estimate
the numbers of cells using \texttt{f(t)} or \texttt{g(t)}. We can apply
a model selection in this case between the two growth process.
Additionally, the counting process is subejct to a large amount of
noise. Therefore, finding the ideal model selection method under noisy
conditions describes problem to solve. In this case, the ideal model
selection would favour a growth function that is able to find the true
growth process along with the parameters associated to it. Furthermore,
it is interesting for the researcher to be able to jauge the uncertainty
surrounding the selected model and the parameters

Within this context, the data generated was meant to mimic a growth
process through time. \texttt{x} represents the time through which the
count increases. To bound the problem the count was normalized (min-max
normalization) :

\texttt{x\ belongs\ to\ {[}0,\ 1000{]}}
\texttt{y\ belongs\ to\ {[}0\ and\ 1{]}}

The two growth functions used to generate the data were a simple linear
function (1) and a logistic function (2) of the following forms :

\texttt{f(t)\ =\ alpha\ +\ beta\ *\ x\ (1)} where \texttt{alpha} is the
intercept and \texttt{beta} the the coefficient of \texttt{x} and :

\texttt{g(t)\ =\ L/(1\ +\ \ e\^{}(-k(x\ -\ x0)))\ (2)} where \texttt{L}
describes the maximum value the curve could take, \texttt{k} describes
the growth rate of the logistic function and \texttt{x0} represents the
sigmoid's midpoint.

For all these parameters, the following values were uniformly drawn : *
alpha \textasciitilde{} U{[}0, 0.05{]} * beta \textasciitilde{}
U{[}0,0.2{]} * L \textasciitilde{} U{[}0.9, 1.1{]} * x0
\textasciitilde{} U{[}1/4 * max(x) , 3/4 * max(x){]} * k
\textasciitilde{} U{[}0.5, 2{]}

In order to simulate the noise in the problem and analyze it in a
coherent manner different levels of additive Gaussian errors were added
ranging. The Gaussian errors all had a mean of 0 and a a variance
\texttt{sigma} ranging from 0.1 to 1 by intervals of 0.1. In the
following discussion we refer to each of these noise levels as noise
buckets. Each noise bucket was conprised of 1000 synthetic datasets.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

Here each subsection can correspond to one interest point of the
experiment (e.g.~adding drift, taking only the certain quartiles of the
signal\ldots{}). Each subsection can be divided into curve fitting led
approches and bayesian approaches - With ultimately a pipeline in mind
as end goal. The data is divided into bucket so that the overall dataset
looks like this : (dataset contains the numpy arrays of the data in
question, varriance\_bucket is the variance of the error going from 0 to
1 - when 1 the error is std normal, drift\_line is BOOL describes if a
drift line was added to the signal and functional form is ``logistic''
or ``linear'' )

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(dplyr}\OperatorTok{::}\KeywordTok{tibble}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"dataset"}\NormalTok{, }\StringTok{"variance_bucket"}\NormalTok{, }\StringTok{"drift_line"}\NormalTok{, }\StringTok{"functional_form"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 1
##   `c("dataset", "variance_bucket", "drift_line", "functional_form")`
##   <chr>                                                             
## 1 dataset                                                           
## 2 variance_bucket                                                   
## 3 drift_line                                                        
## 4 functional_form
\end{verbatim}

\hypertarget{frequentist---curve-fitting}{%
\subsection{Frequentist - curve
fitting}\label{frequentist---curve-fitting}}

\begin{itemize}
\tightlist
\item
  find how we would tackle systematic error in this case - TBD
\end{itemize}

\hypertarget{bayesian-model-selection}{%
\subsection{Bayesian model selection}\label{bayesian-model-selection}}

\begin{itemize}
\tightlist
\item
  find how we would tackle systematic error in this case - Ed Harris
  \#\#
\end{itemize}

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

\hypertarget{evaluation-reflections-and-conclusions}{%
\section{Evaluation, Reflections, and
Conclusions}\label{evaluation-reflections-and-conclusions}}


\end{document}
